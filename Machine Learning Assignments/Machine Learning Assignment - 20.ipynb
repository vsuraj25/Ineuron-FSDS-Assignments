{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "# 1. What is the underlying concept of Support Vector Machines ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7b03a",
   "metadata": {},
   "source": [
    "# Answer\n",
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "# 2. What is the concept of a support vector ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745a587",
   "metadata": {},
   "source": [
    "# Answer\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "# 3. When using SVMs, why is it necessary to scale the inputs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8db91c",
   "metadata": {},
   "source": [
    "# Answer\n",
    "Because Support Vector Machine (SVM) optimization occurs by minimizing the decision vector w, the optimal hyperplane is influenced by the scale of the input features and it's therefore recommended that data be standardized (mean 0, var 1) prior to SVM model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "# 4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ae9b4",
   "metadata": {},
   "source": [
    "# Answer\n",
    "An SVM classifier can give the distance between the test instance and the decision boundary as output, so we can use that as a confidence score, but we cannot use this score to directly converted it into class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "##### 5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form of the SVM problem ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b695efe",
   "metadata": {},
   "source": [
    "Primal form should be used for large instances of data for SVM Problem as it is much more optimistic and fast than the dual form. Training with dual form will take lot of time for execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "# 6. Let's say you've used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it better to raise or lower (gamma)? What about the letter C ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae674f8",
   "metadata": {},
   "source": [
    "# Answer\n",
    "If we trained an SVM classifier using a Radial Basis Function (RBF) kernel, then it underfits the training set, so there might be too much regularization. To decrease it, you need to increase the gamma or C hyper-parameter.\n",
    "\n",
    "C is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly. Increasing C values may lead to overfitting the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "# 7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters (H, f, A, and b) be set ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ac2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "# 8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if you can get them to make a model that is similar to yours ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f716511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "setosa_or_versicolor = (y == 0) | (y == 1)\n",
    "X = X[setosa_or_versicolor]\n",
    "y = y[setosa_or_versicolor]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d748ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3c61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 5\n",
    "alpha = 1 / (C * len(X))\n",
    "\n",
    "lin_clf = LinearSVC(loss=\"hinge\", C=C, random_state=42)\n",
    "svm_clf = SVC(kernel=\"linear\", C=C)\n",
    "sgd_clf = SGDClassifier(loss=\"hinge\", learning_rate=\"constant\", eta0=0.001, alpha=alpha,\n",
    "                        max_iter=1000, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a84f445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.002, eta0=0.001, learning_rate='constant',\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "lin_clf.fit(X_scaled, y)\n",
    "svm_clf.fit(X_scaled, y)\n",
    "sgd_clf.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f629f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:                    [0.28475098] [[1.05364854 1.09903804]]\n",
      "SVC:                          [0.31896852] [[1.1203284  1.02625193]]\n",
      "SGDClassifier(alpha=0.00200): [0.117] [[0.77714169 0.72981762]]\n"
     ]
    }
   ],
   "source": [
    "print(\"LinearSVC:                   \", lin_clf.intercept_, lin_clf.coef_)\n",
    "print(\"SVC:                         \", svm_clf.intercept_, svm_clf.coef_)\n",
    "print(\"SGDClassifier(alpha={:.5f}):\".format(sgd_clf.alpha), sgd_clf.intercept_, sgd_clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0f9b5",
   "metadata": {},
   "source": [
    "As you see based on the coefficient and intercept LinearSVC and SVC doesn't vary that much whereas SGDClassifier differs a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "# 9. On the MNIST dataset, train an SVM classifier. You'll need to use one-versus-the-rest to assign all 10 digits because SVM classifiers are binary classifiers. To accelerate up the process, you might want to tune the hyperparameters using small validation sets. What level of precision can you achieve ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d926bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dea2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc6175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = scaler.transform(X_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391e3600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(gamma=\"scale\")\n",
    "svm_clf.fit(X_train_scaled[:10000], y_train[:10000]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34978440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9455333333333333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb9d7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ....C=5.091151980696917, gamma=0.006528329233814738; total time=   0.4s\n",
      "[CV] END ....C=5.091151980696917, gamma=0.006528329233814738; total time=   0.4s\n",
      "[CV] END ....C=5.091151980696917, gamma=0.006528329233814738; total time=   0.4s\n",
      "[CV] END ..C=2.6852295900238112, gamma=0.0033540375918657286; total time=   0.3s\n",
      "[CV] END ..C=2.6852295900238112, gamma=0.0033540375918657286; total time=   0.4s\n",
      "[CV] END ..C=2.6852295900238112, gamma=0.0033540375918657286; total time=   0.3s\n",
      "[CV] END ....C=6.084799639388057, gamma=0.015256751466043737; total time=   0.4s\n",
      "[CV] END ....C=6.084799639388057, gamma=0.015256751466043737; total time=   0.4s\n",
      "[CV] END ....C=6.084799639388057, gamma=0.015256751466043737; total time=   0.4s\n",
      "[CV] END ...C=3.2942367008397992, gamma=0.002093954922373084; total time=   0.3s\n",
      "[CV] END ...C=3.2942367008397992, gamma=0.002093954922373084; total time=   0.3s\n",
      "[CV] END ...C=3.2942367008397992, gamma=0.002093954922373084; total time=   0.3s\n",
      "[CV] END .....C=5.745138574347426, gamma=0.00955732933459388; total time=   0.4s\n",
      "[CV] END .....C=5.745138574347426, gamma=0.00955732933459388; total time=   0.6s\n",
      "[CV] END .....C=5.745138574347426, gamma=0.00955732933459388; total time=   0.6s\n",
      "[CV] END ..C=3.6670663559753316, gamma=0.0018527556701320854; total time=   0.4s\n",
      "[CV] END ..C=3.6670663559753316, gamma=0.0018527556701320854; total time=   0.3s\n",
      "[CV] END ..C=3.6670663559753316, gamma=0.0018527556701320854; total time=   0.3s\n",
      "[CV] END ...C=9.913936656243619, gamma=0.0017029752991677674; total time=   0.3s\n",
      "[CV] END ...C=9.913936656243619, gamma=0.0017029752991677674; total time=   0.3s\n",
      "[CV] END ...C=9.913936656243619, gamma=0.0017029752991677674; total time=   0.3s\n",
      "[CV] END ..C=5.2414161836423805, gamma=0.0010421197249874635; total time=   0.3s\n",
      "[CV] END ..C=5.2414161836423805, gamma=0.0010421197249874635; total time=   0.3s\n",
      "[CV] END ..C=5.2414161836423805, gamma=0.0010421197249874635; total time=   0.3s\n",
      "[CV] END ....C=4.081882489086185, gamma=0.013590290342288125; total time=   0.4s\n",
      "[CV] END ....C=4.081882489086185, gamma=0.013590290342288125; total time=   0.4s\n",
      "[CV] END ....C=4.081882489086185, gamma=0.013590290342288125; total time=   0.4s\n",
      "[CV] END ....C=3.4150120442451417, gamma=0.08397506097581175; total time=   0.4s\n",
      "[CV] END ....C=3.4150120442451417, gamma=0.08397506097581175; total time=   0.5s\n",
      "[CV] END ....C=3.4150120442451417, gamma=0.08397506097581175; total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002F27F872F08>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002F27F894A08>},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdacc636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5.2414161836423805, gamma=0.0010421197249874635)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d835e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649967332602063"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcd8b4",
   "metadata": {},
   "source": [
    "Training best estimator on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba321ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5.2414161836423805, gamma=0.0010421197249874635)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862c8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Score\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Score\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "# 10. On the California housing dataset, train an SVM regressor ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc128984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
      "       'Latitude', 'Longitude', 'Target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing_data = fetch_california_housing()\n",
    "descr = housing_data['DESCR']\n",
    "feature_names = housing_data['feature_names']\n",
    "data = housing_data['data']\n",
    "target = housing_data['target']\n",
    "df1 = pd.DataFrame(data=data)\n",
    "df1.rename(columns={0: feature_names[0], 1: feature_names[1], 2: feature_names[2], 3: feature_names[3],\n",
    " 4: feature_names[4], 5: feature_names[5], 6: feature_names[6], 7: feature_names[7]}, inplace=True)\n",
    "df2 = pd.DataFrame(data=target)\n",
    "df2.rename(columns={0: 'Target'}, inplace=True)\n",
    "housing = pd.concat([df1, df2], axis=1)\n",
    "print(housing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dc5582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600d1a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      " 8   Target      20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b8881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.loc[:, housing.columns != 'Target'], housing['Target'], random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109b940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² of Support Vector Regressor on training set: -0.023\n",
      "R² of Support Vector Regressor on test set: -0.033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "s1 = svr.score(X_train, y_train)\n",
    "s2 = svr.score(X_test, y_test)\n",
    "print('R² of Support Vector Regressor on training set: {:.3f}'.format(s1))\n",
    "print('R² of Support Vector Regressor on test set: {:.3f}'.format(s2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "82d4c6f819cf47785f735f902f00da8643513d08dab4f4c7470bccf934b8d2d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
